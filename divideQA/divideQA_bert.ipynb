{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ne_NAWIW17BV"
      },
      "source": [
        "## import package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjcgsM7vwcc9",
        "outputId": "a4165ad5-a9a6-4371-860f-86b6a84122c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/shuxian109504502/anaconda3/envs/AICUP/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import CrossEntropyLoss\n",
        "import math\n",
        "import numpy as np\n",
        "import time\n",
        "import torch, pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "import pickle\n",
        "import os\n",
        "# nltk.download('punkt')\n",
        "\n",
        "from transformers import set_seed\n",
        "set_seed(123)\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SYk_hc2dpscj"
      },
      "outputs": [],
      "source": [
        "# Training data file\n",
        "\n",
        "file=\"../data/divide_QA_data/data_fix_label_to_sen.pkl\"\n",
        "with open(file, 'rb') as f:\n",
        "    data = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>q</th>\n",
              "      <th>r</th>\n",
              "      <th>s</th>\n",
              "      <th>q'</th>\n",
              "      <th>r'</th>\n",
              "      <th>q_label</th>\n",
              "      <th>r_label</th>\n",
              "      <th>q_reidx</th>\n",
              "      <th>r_reidx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8</td>\n",
              "      <td>It can go both ways . We all doubt . It is wha...</td>\n",
              "      <td>True .</td>\n",
              "      <td>AGREE</td>\n",
              "      <td>It can go both ways . We all doubt . It is wha...</td>\n",
              "      <td>True .</td>\n",
              "      <td>(0, 76)</td>\n",
              "      <td>(0, 5)</td>\n",
              "      <td>(0, 76)</td>\n",
              "      <td>(0, 5)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8</td>\n",
              "      <td>It can go both ways . We all doubt . It is wha...</td>\n",
              "      <td>True .</td>\n",
              "      <td>AGREE</td>\n",
              "      <td>can go both ways . We all doubt . It is what y...</td>\n",
              "      <td>True</td>\n",
              "      <td>(3, 74)</td>\n",
              "      <td>(0, 3)</td>\n",
              "      <td>(0, 76)</td>\n",
              "      <td>(0, 5)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>It can go both ways . We all doubt . It is wha...</td>\n",
              "      <td>True .</td>\n",
              "      <td>AGREE</td>\n",
              "      <td>It can go both ways . We all doubt . It is wha...</td>\n",
              "      <td>True</td>\n",
              "      <td>(0, 76)</td>\n",
              "      <td>(0, 3)</td>\n",
              "      <td>(0, 76)</td>\n",
              "      <td>(0, 5)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>once again , you seem to support the killing o...</td>\n",
              "      <td>based on the idea that people are dispensible ...</td>\n",
              "      <td>AGREE</td>\n",
              "      <td>seem to support the killing of certain people</td>\n",
              "      <td>based on the idea that people are dispensible ...</td>\n",
              "      <td>(17, 61)</td>\n",
              "      <td>(0, 92)</td>\n",
              "      <td>(0, 81)</td>\n",
              "      <td>(0, 337)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9</td>\n",
              "      <td>once again , you seem to support the killing o...</td>\n",
              "      <td>based on the idea that people are dispensible ...</td>\n",
              "      <td>AGREE</td>\n",
              "      <td>you seem to support the killing of certain peo...</td>\n",
              "      <td>based on the idea that people are dispensible</td>\n",
              "      <td>(13, 81)</td>\n",
              "      <td>(0, 44)</td>\n",
              "      <td>(0, 81)</td>\n",
              "      <td>(0, 337)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36867</th>\n",
              "      <td>10001</td>\n",
              "      <td>good thing this argument has never been done !...</td>\n",
              "      <td>And teen sex does n't , by the very nature of ...</td>\n",
              "      <td>DISAGREE</td>\n",
              "      <td>You are much better off making theft legal and...</td>\n",
              "      <td>And teen sex does n't , by the very nature of ...</td>\n",
              "      <td>(111, 227)</td>\n",
              "      <td>(0, 57)</td>\n",
              "      <td>(0, 227)</td>\n",
              "      <td>(0, 200)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36868</th>\n",
              "      <td>10002</td>\n",
              "      <td>I know one thing , anything that happens , pol...</td>\n",
              "      <td>Was n't sinjin crowing about his plans to take...</td>\n",
              "      <td>DISAGREE</td>\n",
              "      <td>I know one thing , anything that happens , pol...</td>\n",
              "      <td>Was n't sinjin crowing about his plans to take...</td>\n",
              "      <td>(0, 108)</td>\n",
              "      <td>(0, 76)</td>\n",
              "      <td>(0, 643)</td>\n",
              "      <td>(0, 260)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36869</th>\n",
              "      <td>10002</td>\n",
              "      <td>I know one thing , anything that happens , pol...</td>\n",
              "      <td>Was n't sinjin crowing about his plans to take...</td>\n",
              "      <td>DISAGREE</td>\n",
              "      <td>FBI Arrests Three Men in Terror Plot that Targ...</td>\n",
              "      <td>Was n't sinjin crowing about his plans to take...</td>\n",
              "      <td>(112, 195)</td>\n",
              "      <td>(0, 56)</td>\n",
              "      <td>(0, 643)</td>\n",
              "      <td>(0, 260)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36870</th>\n",
              "      <td>10003</td>\n",
              "      <td>I enjoy Botany more than most things and I hav...</td>\n",
              "      <td>Hi Smallax , welcome to the forum . I did a se...</td>\n",
              "      <td>AGREE</td>\n",
              "      <td>I enjoy Botany more than most things and I hav...</td>\n",
              "      <td>Hi Smallax , welcome to the forum . I did a se...</td>\n",
              "      <td>(0, 106)</td>\n",
              "      <td>(0, 119)</td>\n",
              "      <td>(0, 442)</td>\n",
              "      <td>(0, 266)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36871</th>\n",
              "      <td>10003</td>\n",
              "      <td>I enjoy Botany more than most things and I hav...</td>\n",
              "      <td>Hi Smallax , welcome to the forum . I did a se...</td>\n",
              "      <td>AGREE</td>\n",
              "      <td>bringing in outside sun light through fiber op...</td>\n",
              "      <td>might give you an idea about costs and concept...</td>\n",
              "      <td>(155, 225)</td>\n",
              "      <td>(86, 168)</td>\n",
              "      <td>(0, 442)</td>\n",
              "      <td>(0, 266)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>36872 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          id                                                  q  \\\n",
              "0          8  It can go both ways . We all doubt . It is wha...   \n",
              "1          8  It can go both ways . We all doubt . It is wha...   \n",
              "2          8  It can go both ways . We all doubt . It is wha...   \n",
              "3          9  once again , you seem to support the killing o...   \n",
              "4          9  once again , you seem to support the killing o...   \n",
              "...      ...                                                ...   \n",
              "36867  10001  good thing this argument has never been done !...   \n",
              "36868  10002  I know one thing , anything that happens , pol...   \n",
              "36869  10002  I know one thing , anything that happens , pol...   \n",
              "36870  10003  I enjoy Botany more than most things and I hav...   \n",
              "36871  10003  I enjoy Botany more than most things and I hav...   \n",
              "\n",
              "                                                       r         s  \\\n",
              "0                                                 True .     AGREE   \n",
              "1                                                 True .     AGREE   \n",
              "2                                                 True .     AGREE   \n",
              "3      based on the idea that people are dispensible ...     AGREE   \n",
              "4      based on the idea that people are dispensible ...     AGREE   \n",
              "...                                                  ...       ...   \n",
              "36867  And teen sex does n't , by the very nature of ...  DISAGREE   \n",
              "36868  Was n't sinjin crowing about his plans to take...  DISAGREE   \n",
              "36869  Was n't sinjin crowing about his plans to take...  DISAGREE   \n",
              "36870  Hi Smallax , welcome to the forum . I did a se...     AGREE   \n",
              "36871  Hi Smallax , welcome to the forum . I did a se...     AGREE   \n",
              "\n",
              "                                                      q'  \\\n",
              "0      It can go both ways . We all doubt . It is wha...   \n",
              "1      can go both ways . We all doubt . It is what y...   \n",
              "2      It can go both ways . We all doubt . It is wha...   \n",
              "3          seem to support the killing of certain people   \n",
              "4      you seem to support the killing of certain peo...   \n",
              "...                                                  ...   \n",
              "36867  You are much better off making theft legal and...   \n",
              "36868  I know one thing , anything that happens , pol...   \n",
              "36869  FBI Arrests Three Men in Terror Plot that Targ...   \n",
              "36870  I enjoy Botany more than most things and I hav...   \n",
              "36871  bringing in outside sun light through fiber op...   \n",
              "\n",
              "                                                      r'     q_label  \\\n",
              "0                                                 True .     (0, 76)   \n",
              "1                                                   True     (3, 74)   \n",
              "2                                                   True     (0, 76)   \n",
              "3      based on the idea that people are dispensible ...    (17, 61)   \n",
              "4          based on the idea that people are dispensible    (13, 81)   \n",
              "...                                                  ...         ...   \n",
              "36867  And teen sex does n't , by the very nature of ...  (111, 227)   \n",
              "36868  Was n't sinjin crowing about his plans to take...    (0, 108)   \n",
              "36869  Was n't sinjin crowing about his plans to take...  (112, 195)   \n",
              "36870  Hi Smallax , welcome to the forum . I did a se...    (0, 106)   \n",
              "36871  might give you an idea about costs and concept...  (155, 225)   \n",
              "\n",
              "         r_label   q_reidx   r_reidx  \n",
              "0         (0, 5)   (0, 76)    (0, 5)  \n",
              "1         (0, 3)   (0, 76)    (0, 5)  \n",
              "2         (0, 3)   (0, 76)    (0, 5)  \n",
              "3        (0, 92)   (0, 81)  (0, 337)  \n",
              "4        (0, 44)   (0, 81)  (0, 337)  \n",
              "...          ...       ...       ...  \n",
              "36867    (0, 57)  (0, 227)  (0, 200)  \n",
              "36868    (0, 76)  (0, 643)  (0, 260)  \n",
              "36869    (0, 56)  (0, 643)  (0, 260)  \n",
              "36870   (0, 119)  (0, 442)  (0, 266)  \n",
              "36871  (86, 168)  (0, 442)  (0, 266)  \n",
              "\n",
              "[36872 rows x 10 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['sub_q_true'] = [1 if x != None else -1 for x in data[\"q_label\"]]\n",
        "data['sub_r_true'] = [1 if x != None else -1 for x in data[\"r_label\"]]\n",
        "data['sub_both'] = data['sub_q_true'] * data['sub_r_true']\n",
        "data.drop(index= data[data['sub_both'] == -1].index, inplace=True)\n",
        "data.drop(columns=['sub_q_true', 'sub_r_true', 'sub_both'], inplace=True)\n",
        "data.reset_index(drop=True, inplace=True)\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-O0ShLN5PY5"
      },
      "source": [
        "## Data process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "sra75dJjjZwC"
      },
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "train = data[:int(len(data)*0.9)].copy()\n",
        "valid = data[int(len(data)*0.9):].copy()\n",
        "del data\n",
        "# train, valid = train_test_split(data, test_size=1/9, shuffle=False)\n",
        "# valid, test = train_test_split(valid, test_size=0.5)\n",
        "train.reset_index(drop=True, inplace=True)\n",
        "valid.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "train[\"s+r\"] = train[\"s\"] + \": \" + train[\"r\"]\n",
        "valid[\"s+r\"] = valid[\"s\"] + \": \" + valid[\"r\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcQn-_Rq5yfT"
      },
      "source": [
        "## Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "kJNMGgErziHa"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "MODEL_NAME = \"bert-base-cased\"\n",
        "# MODEL_NAME = \"deepset/roberta-base-squad2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "TozH0A1pm2bv"
      },
      "outputs": [],
      "source": [
        "train_data_q = train['q'].tolist()\n",
        "valid_data_q = valid['q'].tolist()\n",
        "# test_data_q = test['q'].tolist()\n",
        "\n",
        "train_data_r = train['s+r'].tolist()\n",
        "valid_data_r = valid['s+r'].tolist()\n",
        "# train_data_r = train['r'].tolist()\n",
        "# valid_data_r = valid['r'].tolist()\n",
        "# test_data_r = test['r'].tolist()\n",
        "\n",
        "train_s = train['s'].tolist()\n",
        "valid_s = valid['s'].tolist()\n",
        "\n",
        "train_q_label = train['q_label'].tolist()\n",
        "valid_q_label = valid['q_label'].tolist()\n",
        "\n",
        "train_r_label = train['r_label'].tolist()\n",
        "valid_r_label = valid['r_label'].tolist()\n",
        "\n",
        "train_q_reidx = train['q_reidx'].tolist()\n",
        "valid_q_reidx = valid['q_reidx'].tolist()\n",
        "# test_q_reidx = test['q_reidx'].tolist()\n",
        "\n",
        "train_r_reidx = train['r_reidx'].tolist()\n",
        "valid_r_reidx = valid['r_reidx'].tolist()\n",
        "# test_r_reidx = test['r_reidx'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "a4-Xb_k1kfyv"
      },
      "outputs": [],
      "source": [
        "train_encodings = tokenizer(train_data_q, train_data_r, truncation=True, padding=True, max_length=512)\n",
        "val_encodings = tokenizer(valid_data_q, valid_data_r, truncation=True, padding=True, max_length=512, return_offsets_mapping=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGfziDMh6iOP"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_token_positions(encodings, q_label, r_label, q_reidx, r_reidx, s_data=None):\n",
        "    if s_data is not None:\n",
        "        for idx, s in enumerate(s_data):\n",
        "            if s == \"AGREE\":\n",
        "                r_label[idx] = (r_label[idx][0] + 7, r_label[idx][1] + 7) if r_label[idx] != None else None\n",
        "            elif s == \"DISAGREE\":\n",
        "                r_label[idx] = (r_label[idx][0] + 10, r_label[idx][1] + 10) if r_label[idx] != None else None\n",
        "    q_starts, r_starts, q_ends, r_ends = [], [], [], []\n",
        "    for idx, (q_l, q_r, r_l, r_r) in enumerate(zip(q_label, q_reidx, r_label, r_reidx)):\n",
        "        # q_start, q_end, r_start, r_end = 0, 0, 0, 0\n",
        "\n",
        "        if q_l == None or r_l == None:\n",
        "            q_starts.append(0)\n",
        "            q_ends.append(0)\n",
        "            r_starts.append(0)\n",
        "            r_ends.append(0)\n",
        "            continue\n",
        "\n",
        "        q_s = encodings.char_to_token(idx, q_l[0]-q_r[0], 0)\n",
        "        q_e = encodings.char_to_token(idx, q_l[1]-q_r[0], 0)\n",
        "\n",
        "        r_s = encodings.char_to_token(idx, r_l[0]-r_r[0], 1)    #2\n",
        "        r_e = encodings.char_to_token(idx, r_l[1]-r_r[0], 1)\n",
        "\n",
        "        if q_s == None and q_e == None or r_s == None and r_e == None:\n",
        "            q_starts.append(0)\n",
        "            q_ends.append(0)\n",
        "            r_starts.append(0)\n",
        "            r_ends.append(0)\n",
        "            continue\n",
        "\n",
        "        shift = 1\n",
        "        while q_s is None:\n",
        "            q_s = encodings.char_to_token(idx, q_l[0]-q_r[0] + shift, 0)\n",
        "            shift += 1\n",
        "        shift = 1\n",
        "        while r_s is None:\n",
        "            r_s = encodings.char_to_token(idx, r_l[0]-r_r[0] + shift, 1)    #2\n",
        "            shift += 1\n",
        "\n",
        "        shift = 1\n",
        "        while q_e is None:\n",
        "            q_e = encodings.char_to_token(idx, q_l[1]-q_r[0] - shift, 0)\n",
        "            shift += 1\n",
        "        shift = 1\n",
        "        while r_e is None:\n",
        "            r_e = encodings.char_to_token(idx, r_l[1]-r_r[0] - shift, 1)    #2\n",
        "            shift += 1\n",
        "            \n",
        "        if q_s == None or q_e == None or r_s == None or r_e == None:\n",
        "            print(idx, q_s, q_e, r_s, r_e)\n",
        "        q_starts.append(q_s)\n",
        "        q_ends.append(q_e)\n",
        "        r_starts.append(r_s)\n",
        "        r_ends.append(r_e)\n",
        "\n",
        "    encodings.update({'q_start': q_starts, 'q_end': q_ends, 'r_start': r_starts, 'r_end': r_ends})\n",
        "    return r_label, r_reidx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "A1xqKVrBwSHx"
      },
      "outputs": [],
      "source": [
        "# Convert char_based_id to token_based_id\n",
        "# Find the corossponding token id after input being tokenized\n",
        "train_r_label, train_r_reidx =  add_token_positions(train_encodings, train_q_label, train_r_label, train_q_reidx, train_r_reidx, train_s)\n",
        "valid_r_label, valid_r_reidx =  add_token_positions(val_encodings, valid_q_label, valid_r_label, valid_q_reidx, valid_r_reidx, valid_s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Awivv8SdNm_d"
      },
      "outputs": [],
      "source": [
        "class qrDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # item = {}\n",
        "        # for key, val in self.encodings.items():\n",
        "        #     if key != 'offset_mapping':\n",
        "        #         item[key] = torch.tensor(val[idx])\n",
        "        # return item\n",
        "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "yIjnUh9qOEjD"
      },
      "outputs": [],
      "source": [
        "val_mappping = val_encodings['offset_mapping']\n",
        "val_encodings.pop(\"offset_mapping\")\n",
        "train_dataset = qrDataset(train_encodings)\n",
        "val_dataset = qrDataset(val_encodings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZhJSrR7xTjv",
        "outputId": "f99c03c1-d4b9-4f3a-90b5-9b311eb9fc6f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'q_start', 'q_end', 'r_start', 'r_end']),\n",
              " dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'q_start', 'q_end', 'r_start', 'r_end']))"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset.encodings.keys(), val_dataset.encodings.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anB_LCU16q-C"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "rwZdH-I4PoAf"
      },
      "outputs": [],
      "source": [
        "from transformers import BertModel\n",
        "\n",
        "class myModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super(myModel, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained(MODEL_NAME)\n",
        "        self.fc = nn.Linear(768, 4)\n",
        "        \n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids=None):   \n",
        "        # output = self.bert(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        output = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        output_logits = self.fc(output[0])\n",
        "        return output_logits\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEUJSg7E6wWF"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "JIwySrYN9EOp"
      },
      "outputs": [],
      "source": [
        "# # Pack data into dataloader by batch\n",
        "batch_size = 8\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIZ50YA8OfgB",
        "outputId": "bf24afe9-4b0c-4421-b8cd-69d584db4799"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from tqdm.auto import tqdm\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "\n",
        "# Set GPU / CPU\n",
        "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "# Put model on device\n",
        "model = myModel().to(device)\n",
        "training_epoch = 3\n",
        "loss_fct = CrossEntropyLoss()\n",
        "\n",
        "# params = list(model.named_parameters())\n",
        "# no_decay = ['bias,','LayerNorm']\n",
        "# other = ['fc']\n",
        "# no_main = no_decay + other\n",
        "\n",
        "# optimizer_grouped_parameters = [\n",
        "#     {'params':[p for n,p in params if not any(nd in n for nd in no_main)],'weight_decay':1e-2,'lr':1e-5},\n",
        "#     {'params':[p for n,p in params if not any(nd in n for nd in other) and any(nd in n for nd in no_decay) ],'weight_decay':0,'lr':1e-5},\n",
        "#     {'params':[p for n,p in params if any(nd in n for nd in other) and any(nd in n for nd in no_decay) ],'weight_decay':0,'lr':1e-2},\n",
        "#     {'params':[p for n,p in params if any(nd in n for nd in other) and not any(nd in n for nd in no_decay) ],'weight_decay':1e-2,'lr':1e-2},\n",
        "# ]\n",
        "optim = AdamW(model.parameters(), lr=1e-5)\n",
        "\n",
        "total_steps = len(train_loader) * training_epoch\n",
        "\n",
        "# optimizer = optim.Adam(model.parameters(), lr=learning_rate0)\n",
        "\n",
        "# optim = AdamW(optimizer_grouped_parameters, lr=1e-5)\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optim,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SUC-vq-70Ye"
      },
      "source": [
        "### Grading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "vIXjyoo3Sgb0"
      },
      "outputs": [],
      "source": [
        "def get_output_post_fn(test, q_sub_output, r_sub_output):\n",
        "    q_sub, r_sub = [], []\n",
        "    for i in range(len(test)):\n",
        "\n",
        "        q_sub_pred = q_sub_output[i].split()\n",
        "        r_sub_pred = r_sub_output[i].split()\n",
        "\n",
        "        if q_sub_pred is None:\n",
        "            q_sub_pred = []\n",
        "        q_sub_error_index = q_sub_pred.index('[SEP]') if '[SEP]' in q_sub_pred else -1\n",
        "\n",
        "        if q_sub_error_index != -1:\n",
        "            q_sub_pred = q_sub_pred[:q_sub_error_index]\n",
        "\n",
        "        temp = r_sub_pred.copy()\n",
        "        if r_sub_pred is None:\n",
        "            r_sub_pred = []\n",
        "        else:\n",
        "            for j in range(len(temp)):\n",
        "                if temp[j] == '[SEP]':\n",
        "                    r_sub_pred.remove('[SEP]')\n",
        "                if temp[j] == '[PAD]':\n",
        "                    r_sub_pred.remove('[PAD]')\n",
        "\n",
        "        q_sub.append(' '.join(q_sub_pred))\n",
        "        r_sub.append(' '.join(r_sub_pred))\n",
        "        if q_sub[-1] == \"[CLS]\":\n",
        "            q_sub[-1] = test[\"q\"][len(q_sub)-1]\n",
        "        if r_sub[-1] == \"[CLS]\":\n",
        "            r_sub[-1] = test[\"r\"][len(r_sub)-1]\n",
        "\n",
        "    return q_sub, r_sub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "S6QjZ3G5fL90"
      },
      "outputs": [],
      "source": [
        "def nltk_token_string(sentence):\n",
        "    # print(sentence)\n",
        "    tokens = nltk.word_tokenize(sentence)\n",
        "    for i in range(len(tokens)):\n",
        "        if len(tokens[i]) == 1:\n",
        "            tokens[i] = re.sub(r\"[!\\\"#$%&\\'()*\\+, -.\\/:;<=>?@\\[\\\\\\]^_`{|}~]\", '', tokens[i])\n",
        "    while '' in tokens:\n",
        "        tokens.remove('')\n",
        "    # tokens = ' '.join(tokens)\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "xYkzHmd6K9FY"
      },
      "outputs": [],
      "source": [
        "def lcs(X, Y):\n",
        "    X_, Y_ = [], []\n",
        "    X_ = nltk_token_string(X)\n",
        "    Y_ = nltk_token_string(Y)\n",
        "\n",
        "    m = len(X_)\n",
        "    n = len(Y_)\n",
        " \n",
        "    # declaring the array for storing the dp values\n",
        "    L = [[None]*(n + 1) for i in range(m + 1)]\n",
        " \n",
        "    \"\"\"Following steps build L[m + 1][n + 1] in bottom up fashion\n",
        "    Note: L[i][j] contains length of LCS of X[0..i-1]\n",
        "    and Y[0..j-1]\"\"\"\n",
        "    for i in range(m + 1):\n",
        "        for j in range(n + 1):\n",
        "            if i == 0 or j == 0 :\n",
        "                L[i][j] = 0\n",
        "            elif X_[i-1] == Y_[j-1]:\n",
        "                L[i][j] = L[i-1][j-1]+1\n",
        "            else:\n",
        "                L[i][j] = max(L[i-1][j], L[i][j-1])\n",
        " \n",
        "    # L[m][n] contains the length of LCS of X[0..n-1] & Y[0..m-1]\n",
        "    return L[m][n], m, n\n",
        "\n",
        "\n",
        "def acc_(full, sub):\n",
        "    common, m, n = lcs(full, sub)\n",
        "    union = m + n - common\n",
        "    if union == 0:\n",
        "        return 1\n",
        "    accuracy = float(common/union)\n",
        "\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_acc(q_true, r_true, q_sub, r_sub):\n",
        "    q_acc_sum = 0\n",
        "    r_acc_sum = 0\n",
        "    test_len = len(q_true)\n",
        "    for i in range(test_len):\n",
        "        q_accuracy = acc_(q_true[i], q_sub[i])\n",
        "        r_accuracy = acc_(r_true[i], r_sub[i])\n",
        "\n",
        "        q_acc_sum += q_accuracy\n",
        "        r_acc_sum += r_accuracy\n",
        "\n",
        "    print(\"q accuracy: \", q_acc_sum/test_len)\n",
        "    print(\"r accuracy: \", r_acc_sum/test_len)\n",
        "    return q_acc_sum/test_len, r_acc_sum/test_len"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "6eJKdcP3tdU5"
      },
      "outputs": [],
      "source": [
        "def evaluate(valid_loader, valid_r, valid_q):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    total_loss = 0.0\n",
        "    predict_pos, q_sub_output, r_sub_output = [], [], []\n",
        "    q_true_output, r_true_output = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        loop = tqdm(valid_loader, leave=True, ncols=75)\n",
        "        for batch_id, batch in enumerate(loop):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            token_type_ids = batch['token_type_ids'].to(device)\n",
        "            q_start = batch['q_start'].to(device)\n",
        "            r_start = batch['r_start'].to(device)\n",
        "            q_end = batch['q_end'].to(device)\n",
        "            r_end = batch['r_end'].to(device)\n",
        "\n",
        "            # model output\n",
        "            # outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "\n",
        "            q_start_logits, r_start_logits, q_end_logits, r_end_logits = torch.split(outputs, 1, 2)\n",
        "\n",
        "            q_start_logits = q_start_logits.squeeze(-1).contiguous()\n",
        "            r_start_logits = r_start_logits.squeeze(-1).contiguous()\n",
        "            q_end_logits = q_end_logits.squeeze(-1).contiguous()\n",
        "            r_end_logits = r_end_logits.squeeze(-1).contiguous()\n",
        "\n",
        "            q_start_loss = loss_fct(q_start_logits, q_start)\n",
        "            r_start_loss = loss_fct(r_start_logits, r_start)\n",
        "            q_end_loss = loss_fct(q_end_logits, q_end)\n",
        "            r_end_loss = loss_fct(r_end_logits, r_end)\n",
        "\n",
        "            loss = q_start_loss + r_start_loss + q_end_loss + r_end_loss\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "            if batch_id % 250 == 0 and batch_id != 0:\n",
        "                print('Validation Epoch {} Batch {} Loss {:.4f}'.format(\n",
        "                    batch_id + 1, batch_id, running_loss / 250))\n",
        "                running_loss = 0.0\n",
        "\n",
        "            q_start_prdict = torch.argmax(q_start_logits, 1).cpu().numpy()\n",
        "            r_start_prdict = torch.argmax(r_start_logits, 1).cpu().numpy()\n",
        "            q_end_prdict = torch.argmax(q_end_logits, 1).cpu().numpy()\n",
        "            r_end_prdict = torch.argmax(r_end_logits, 1).cpu().numpy()\n",
        "            # print(q_start_prdict, r_start_prdict, q_end_prdict, r_end_prdict)\n",
        "            for i in range(len(input_ids)):\n",
        "                predict_pos.append((q_start_prdict[i].item(), r_start_prdict[i].item(), q_end_prdict[i].item(), r_end_prdict[i].item()))\n",
        "\n",
        "                q_true_s = val_mappping[batch_size * batch_id + i][q_start[i]][0]\n",
        "                q_true_e = val_mappping[batch_size * batch_id + i][q_end[i]][-1]\n",
        "                r_true_s = val_mappping[batch_size * batch_id + i][r_start[i]][0]\n",
        "                r_true_e = val_mappping[batch_size * batch_id + i][r_end[i]][-1]\n",
        "                q_true = valid_q[batch_size * batch_id + i][q_true_s:q_true_e]\n",
        "                r_true = valid_r[batch_size * batch_id + i][r_true_s:r_true_e]\n",
        "\n",
        "                q_s = val_mappping[batch_size * batch_id + i][predict_pos[-1][0]][0]\n",
        "                q_e = val_mappping[batch_size * batch_id + i][predict_pos[-1][2]][-1]\n",
        "                r_s = val_mappping[batch_size * batch_id + i][predict_pos[-1][1]][0]\n",
        "                r_e = val_mappping[batch_size * batch_id + i][predict_pos[-1][3]][-1]\n",
        "                q_sub = valid_q[batch_size * batch_id + i][q_s:q_e]\n",
        "                r_sub = valid_r[batch_size * batch_id + i][r_s:r_e]\n",
        "\n",
        "                q_sub_output.append(q_sub)\n",
        "                r_sub_output.append(r_sub)\n",
        "                q_true_output.append(q_true)\n",
        "                r_true_output.append(r_true)\n",
        "\n",
        "        print(\"evaluate loss: \", total_loss / len(valid_loader))\n",
        "        # q_sub, r_sub = get_output_post_fn(valid, q_sub_output, r_sub_output)\n",
        "    return q_sub_output, r_sub_output, q_true_output, r_true_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RIFNMy0WHvk",
        "outputId": "9c97ba42-327e-4b67-9fa6-f5ab22a745d9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  45%|██████▋        | 501/1125 [03:50<04:36,  2.26it/s, loss=11.8]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 501 Batch 500 Loss 11.8277\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  89%|████████████▍ | 1001/1125 [07:42<00:57,  2.17it/s, loss=10.4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1001 Batch 1000 Loss 9.0669\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████████| 1125/1125 [08:39<00:00,  2.17it/s, loss=10.3]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1125 Batch 1124 Loss 8.8425\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████| 125/125 [00:19<00:00,  6.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluate loss:  9.143227420806884\n",
            "q accuracy:  0.5091153116873126\n",
            "r accuracy:  0.5033085593666576\n",
            "acc: 0.5062119355269852\n",
            "save model----acc:  0.5062119355269852\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  45%|██████▋        | 501/1125 [03:52<04:55,  2.11it/s, loss=8.51]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 501 Batch 500 Loss 8.5234\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  89%|████████████▍ | 1001/1125 [07:45<00:56,  2.18it/s, loss=8.54]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1001 Batch 1000 Loss 8.5673\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|██████████████| 1125/1125 [08:42<00:00,  2.15it/s, loss=8.55]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1125 Batch 1124 Loss 8.5834\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████| 125/125 [00:19<00:00,  6.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluate loss:  9.029457206726073\n",
            "q accuracy:  0.5056663274236893\n",
            "r accuracy:  0.510552382399677\n",
            "acc: 0.5081093549116832\n",
            "save model----acc:  0.5081093549116832\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  45%|██████▋        | 501/1125 [03:52<04:44,  2.19it/s, loss=8.13]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 501 Batch 500 Loss 8.1424\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  89%|████████████▍ | 1001/1125 [07:44<00:56,  2.18it/s, loss=8.16]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1001 Batch 1000 Loss 8.2001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|██████████████| 1125/1125 [08:42<00:00,  2.15it/s, loss=8.19]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1125 Batch 1124 Loss 8.3000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████| 125/125 [00:19<00:00,  6.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluate loss:  9.143028686523438\n",
            "q accuracy:  0.5061502005370291\n",
            "r accuracy:  0.5102139529881575\n",
            "acc: 0.5081820767625933\n",
            "save model----acc:  0.5081820767625933\n"
          ]
        }
      ],
      "source": [
        "best_acc = 0.0\n",
        "for epoch in range(training_epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    total_loss = 0.0\n",
        "\n",
        "    loop = tqdm(train_loader, leave=True, ncols=75)\n",
        "\n",
        "    for batch_id, batch in enumerate(loop):\n",
        "        # reset\n",
        "        optim.zero_grad()\n",
        "\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        token_type_ids = batch['token_type_ids'].to(device)\n",
        "        q_start = batch['q_start'].to(device)\n",
        "        r_start = batch['r_start'].to(device)\n",
        "        q_end = batch['q_end'].to(device)\n",
        "        r_end = batch['r_end'].to(device)\n",
        "\n",
        "        # model output\n",
        "        # outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "\n",
        "        q_start_logits, r_start_logits, q_end_logits, r_end_logits = torch.split(outputs, 1, 2)\n",
        "\n",
        "        q_start_logits = q_start_logits.squeeze(-1).contiguous()\n",
        "        r_start_logits = r_start_logits.squeeze(-1).contiguous()\n",
        "        q_end_logits = q_end_logits.squeeze(-1).contiguous()\n",
        "        r_end_logits = r_end_logits.squeeze(-1).contiguous()\n",
        "\n",
        "        q_start_loss = loss_fct(q_start_logits, q_start)\n",
        "        r_start_loss = loss_fct(r_start_logits, r_start)\n",
        "        q_end_loss = loss_fct(q_end_logits, q_end)\n",
        "        r_end_loss = loss_fct(r_end_logits, r_end)\n",
        "\n",
        "        loss = q_start_loss + r_start_loss + q_end_loss + r_end_loss\n",
        "\n",
        "        # calculate loss\n",
        "        loss.backward()\n",
        "        running_loss += loss.item()\n",
        "        total_loss += loss.item()\n",
        "        # update parameters\n",
        "        clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optim.step()\n",
        "        scheduler.step()\n",
        "        \n",
        "        if batch_id % 500 == 0 and batch_id != 0 or batch_id == len(train_loader) - 1:\n",
        "            print('Step {} Batch {} Loss {:.4f}'.format(\n",
        "                batch_id + 1, batch_id, (running_loss / 500) if batch_id != len(train_loader) - 1 or(len(train_loader) % 500) ==0 else running_loss / (len(train_loader) % 500)))\n",
        "            running_loss = 0.0\n",
        "\n",
        "        loop.set_description('Epoch {}'.format(epoch + 1))\n",
        "        loop.set_postfix(loss=total_loss/(batch_id+1))\n",
        "    # evaluate(valid_loader)\n",
        "    q_sub_output, r_sub_output, q_true_output, r_true_output = evaluate(valid_loader, valid_data_r, valid_data_q)\n",
        "    # q_sub, r_sub = get_output_post_fn(valid, q_sub_output, r_sub_output)\n",
        "    acc_q, acc_r = get_acc(q_true_output, r_true_output, q_sub_output, r_sub_output)\n",
        "    acc = (acc_q + acc_r) / 2\n",
        "    print(\"acc:\", acc)\n",
        "    if acc > best_acc:\n",
        "        best_acc = acc\n",
        "        best_model_name = str(best_acc)\n",
        "        torch.save(model.state_dict(), best_model_name)\n",
        "        print(\"save model----acc: \", best_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oHM3KS8wNI46"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# model = myModel().to(device)\n",
        "model.load_state_dict(torch.load(best_model_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xi-K6PR7s0_"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "vjSjODbl312a"
      },
      "outputs": [],
      "source": [
        "def predict(test_loader):\n",
        "    predict_pos = []\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    q_sub_output, r_sub_output = [],[]\n",
        "\n",
        "    loop = tqdm(test_loader, leave=True)\n",
        "    for batch_id, batch in enumerate(loop):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        token_type_ids = batch['token_type_ids'].to(device)\n",
        "\n",
        "        # model output\n",
        "        # outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        \n",
        "        q_start_logits, r_start_logits, q_end_logits, r_end_logits = torch.split(outputs, 1, 2)\n",
        "\n",
        "        q_start_logits = q_start_logits.squeeze(-1).contiguous()\n",
        "        r_start_logits = r_start_logits.squeeze(-1).contiguous()\n",
        "        q_end_logits = q_end_logits.squeeze(-1).contiguous()\n",
        "        r_end_logits = r_end_logits.squeeze(-1).contiguous()\n",
        "\n",
        "        q_start_prdict = torch.argmax(q_start_logits, 1).cpu().numpy()\n",
        "        r_start_prdict = torch.argmax(r_start_logits, 1).cpu().numpy()\n",
        "        q_end_prdict = torch.argmax(q_end_logits, 1).cpu().numpy()\n",
        "        r_end_prdict = torch.argmax(r_end_logits, 1).cpu().numpy()\n",
        "\n",
        "        for i in range(len(input_ids)):\n",
        "            predict_pos.append((q_start_prdict[i].item(), r_start_prdict[i].item(), q_end_prdict[i].item(), r_end_prdict[i].item()))\n",
        "            k = 1\n",
        "            while tokenizer.decode(input_ids[i][predict_pos[-1][0]])[0:2] == \"##\":\n",
        "                predict_pos[-1] = (q_start_prdict[i].item()-k, r_start_prdict[i].item(), q_end_prdict[i].item(), r_end_prdict[i].item())\n",
        "                i += 1\n",
        "            k = 1\n",
        "            while tokenizer.decode(input_ids[i][predict_pos[-1][1]])[0:2] == \"##\":\n",
        "                predict_pos[-1] = (q_start_prdict[i].item(), r_start_prdict[i].item(), q_end_prdict[i].item()-k, r_end_prdict[i].item())\n",
        "                i += 1\n",
        "            k = 1\n",
        "\n",
        "            if token_type_ids[i][predict_pos[-1][2]] != 0:\n",
        "                predict_pos[-1] = (q_start_prdict[i].item(), r_start_prdict[i].item(), list(token_type_ids[i]).index(1) - 2, r_end_prdict[i].item())\n",
        "            if token_type_ids[i][predict_pos[-1][1]] != 1:\n",
        "                predict_pos[-1] = (q_start_prdict[i].item(), list(token_type_ids[i]).index(1), q_end_prdict[i].item(), r_end_prdict[i].item())\n",
        "            # q_sub_output.append(q_sub)\n",
        "            # r_sub_output.append(r_sub)\n",
        "    \n",
        "    return predict_pos  #q_sub_output, r_sub_output, predict_pos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/shuxian109504502/anaconda3/envs/AICUP/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  del sys.path[0]\n",
            "/home/shuxian109504502/anaconda3/envs/AICUP/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/home/shuxian109504502/anaconda3/envs/AICUP/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == \"\":\n",
            "/home/shuxian109504502/anaconda3/envs/AICUP/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>q</th>\n",
              "      <th>r</th>\n",
              "      <th>s</th>\n",
              "      <th>q_reidx</th>\n",
              "      <th>r_reidx</th>\n",
              "      <th>q_sub_idx</th>\n",
              "      <th>r_sub_idx</th>\n",
              "      <th>s+r</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2378</th>\n",
              "      <td>5227</td>\n",
              "      <td>Why so many what ?</td>\n",
              "      <td>Different sciences . There are different spins...</td>\n",
              "      <td>AGREE</td>\n",
              "      <td>(0, 17)</td>\n",
              "      <td>(0, 106)</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>AGREE: Different sciences . There are differen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2379</th>\n",
              "      <td>6136</td>\n",
              "      <td>Why would someone make that up and pass it off...</td>\n",
              "      <td>Well , they did .</td>\n",
              "      <td>AGREE</td>\n",
              "      <td>(0, 65)</td>\n",
              "      <td>(0, 16)</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>AGREE: Well , they did .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2380</th>\n",
              "      <td>2271</td>\n",
              "      <td>You once said that you had done a detailed stu...</td>\n",
              "      <td>So doing a detailed study of something require...</td>\n",
              "      <td>DISAGREE</td>\n",
              "      <td>(0, 318)</td>\n",
              "      <td>(0, 210)</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>DISAGREE: So doing a detailed study of somethi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2381</th>\n",
              "      <td>4420</td>\n",
              "      <td>Woodward was a fraud , and I recall that was a...</td>\n",
              "      <td>do you have proof of such a statement ? And wh...</td>\n",
              "      <td>DISAGREE</td>\n",
              "      <td>(0, 77)</td>\n",
              "      <td>(0, 166)</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>DISAGREE: do you have proof of such a statemen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2382</th>\n",
              "      <td>4071</td>\n",
              "      <td>Would you accept civil unions even though they...</td>\n",
              "      <td>No ... and you do n't have to either .</td>\n",
              "      <td>DISAGREE</td>\n",
              "      <td>(0, 71)</td>\n",
              "      <td>(0, 37)</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>DISAGREE: No ... and you do n't have to either .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2383</th>\n",
              "      <td>9499</td>\n",
              "      <td>You are betraying your belief system .</td>\n",
              "      <td>Yep . ( I 'm assuming that by `` belief system...</td>\n",
              "      <td>AGREE</td>\n",
              "      <td>(0, 37)</td>\n",
              "      <td>(0, 270)</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>AGREE: Yep . ( I 'm assuming that by `` belief...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2384</th>\n",
              "      <td>4611</td>\n",
              "      <td>You are in a loud minority , railing against t...</td>\n",
              "      <td>Being in the minority or in the majority is ir...</td>\n",
              "      <td>DISAGREE</td>\n",
              "      <td>(0, 77)</td>\n",
              "      <td>(0, 90)</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>DISAGREE: Being in the minority or in the majo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2385</th>\n",
              "      <td>9328</td>\n",
              "      <td>You bet your XXX that 'd make me happy .</td>\n",
              "      <td>Well , first , I probably would n't bet my XXX...</td>\n",
              "      <td>DISAGREE</td>\n",
              "      <td>(0, 39)</td>\n",
              "      <td>(0, 237)</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>DISAGREE: Well , first , I probably would n't ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2386</th>\n",
              "      <td>5225</td>\n",
              "      <td>you say `` f * * * the Constitution. ``</td>\n",
              "      <td>and gun nuts say f * * * the children when we ...</td>\n",
              "      <td>DISAGREE</td>\n",
              "      <td>(0, 38)</td>\n",
              "      <td>(0, 99)</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>DISAGREE: and gun nuts say f * * * the childre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2387</th>\n",
              "      <td>68</td>\n",
              "      <td>Your answers were without content or meaning ....</td>\n",
              "      <td>k</td>\n",
              "      <td>DISAGREE</td>\n",
              "      <td>(0, 68)</td>\n",
              "      <td>(0, 0)</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>DISAGREE: k</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                                  q  \\\n",
              "2378  5227                                 Why so many what ?   \n",
              "2379  6136  Why would someone make that up and pass it off...   \n",
              "2380  2271  You once said that you had done a detailed stu...   \n",
              "2381  4420  Woodward was a fraud , and I recall that was a...   \n",
              "2382  4071  Would you accept civil unions even though they...   \n",
              "2383  9499             You are betraying your belief system .   \n",
              "2384  4611  You are in a loud minority , railing against t...   \n",
              "2385  9328           You bet your XXX that 'd make me happy .   \n",
              "2386  5225            you say `` f * * * the Constitution. ``   \n",
              "2387    68  Your answers were without content or meaning ....   \n",
              "\n",
              "                                                      r         s   q_reidx  \\\n",
              "2378  Different sciences . There are different spins...     AGREE   (0, 17)   \n",
              "2379                                  Well , they did .     AGREE   (0, 65)   \n",
              "2380  So doing a detailed study of something require...  DISAGREE  (0, 318)   \n",
              "2381  do you have proof of such a statement ? And wh...  DISAGREE   (0, 77)   \n",
              "2382             No ... and you do n't have to either .  DISAGREE   (0, 71)   \n",
              "2383  Yep . ( I 'm assuming that by `` belief system...     AGREE   (0, 37)   \n",
              "2384  Being in the minority or in the majority is ir...  DISAGREE   (0, 77)   \n",
              "2385  Well , first , I probably would n't bet my XXX...  DISAGREE   (0, 39)   \n",
              "2386  and gun nuts say f * * * the children when we ...  DISAGREE   (0, 38)   \n",
              "2387                                                  k  DISAGREE   (0, 68)   \n",
              "\n",
              "       r_reidx  q_sub_idx  r_sub_idx  \\\n",
              "2378  (0, 106)          0          0   \n",
              "2379   (0, 16)          0          0   \n",
              "2380  (0, 210)          0          0   \n",
              "2381  (0, 166)          0          0   \n",
              "2382   (0, 37)          0          0   \n",
              "2383  (0, 270)          0          0   \n",
              "2384   (0, 90)          0          0   \n",
              "2385  (0, 237)          0          0   \n",
              "2386   (0, 99)          0          0   \n",
              "2387    (0, 0)          0          0   \n",
              "\n",
              "                                                    s+r  \n",
              "2378  AGREE: Different sciences . There are differen...  \n",
              "2379                           AGREE: Well , they did .  \n",
              "2380  DISAGREE: So doing a detailed study of somethi...  \n",
              "2381  DISAGREE: do you have proof of such a statemen...  \n",
              "2382   DISAGREE: No ... and you do n't have to either .  \n",
              "2383  AGREE: Yep . ( I 'm assuming that by `` belief...  \n",
              "2384  DISAGREE: Being in the minority or in the majo...  \n",
              "2385  DISAGREE: Well , first , I probably would n't ...  \n",
              "2386  DISAGREE: and gun nuts say f * * * the childre...  \n",
              "2387                                        DISAGREE: k  "
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test = pd.read_csv(\"../data/Batch_answers - test_data(no_label).csv\")\n",
        "test.tail()\n",
        "test[['q','r']] = test[['q','r']].apply(lambda x: x.str.strip('\\\"'))\n",
        "test.tail()\n",
        "def split_sen(data_):    \n",
        "    for i,(j,z) in enumerate(zip(data_[\"q\"], data_[\"r\"])):\n",
        "        # print(i, print(data_[\"q\"][i]))\n",
        "        if len(j.split(\" \")) > 200:\n",
        "            n = math.ceil(len(j.split(\" \"))/200)\n",
        "            tmp = j.split(\" . \")\n",
        "            n = math.ceil(len(tmp)/n)\n",
        "            data_[\"q\"][i] = [(\" . \").join(tmp[idx : idx + n]) for idx in range(0, len(tmp), n)]\n",
        "        else:   data_[\"q\"][i] = [j]\n",
        "        if len(z.split(\" \")) > 200:\n",
        "            n = math.ceil(len(z.split(\" \"))/200)\n",
        "            tmp = z.split(\" . \")\n",
        "            n = math.ceil(len(tmp)/n)\n",
        "            data_[\"r\"][i] = [(\" . \").join(tmp[idx : idx + n]) for idx in range(0, len(tmp), n)]\n",
        "        else:   data_[\"r\"][i] = [z]\n",
        "    return data_\n",
        "\n",
        "def re_idx(array):\n",
        "    idx_list = np.array([len(x) for x in array])+3\n",
        "    idx_list_ = np.cumsum(idx_list)\n",
        "    s_list = idx_list_ - idx_list\n",
        "    idx_list_ -= 4 \n",
        "    return [(x, y ,i) for i,(x,y) in enumerate(zip(s_list, idx_list_))]\n",
        "\n",
        "def re_pair(q, q_redix):\n",
        "    return [[a,b] for (a,b) in zip(q, q_redix)]\n",
        "\n",
        "test = split_sen(test)\n",
        "test[\"q_reidx\"] = test.apply(lambda x : re_idx(x[\"q\"]), axis=1)\n",
        "test[\"r_reidx\"] = test.apply(lambda x : re_idx(x[\"r\"]), axis=1)\n",
        "test[\"q\"] = test.apply(lambda x : re_pair(x[\"q\"], x[\"q_reidx\"]), axis=1)\n",
        "test[\"r\"] = test.apply(lambda x : re_pair(x[\"r\"], x[\"r_reidx\"]), axis=1)\n",
        "test = test.explode('q').reset_index(drop=True)\n",
        "test = test.explode('r').reset_index(drop=True)\n",
        "test[\"q_reidx\"] = test[\"q\"].apply(lambda x : (x[1][0], x[1][1]))\n",
        "test[\"q_sub_idx\"] = test[\"q\"].apply(lambda x : x[1][-1])\n",
        "test[\"q\"] = test[\"q\"].apply(lambda x : x[0])\n",
        "test[\"r_reidx\"] = test[\"r\"].apply(lambda x : (x[1][0], x[1][1]))\n",
        "test[\"r_sub_idx\"] = test[\"r\"].apply(lambda x : x[1][-1])\n",
        "test[\"r\"] = test[\"r\"].apply(lambda x : x[0])\n",
        "test[\"s+r\"] = test[\"s\"] +\": \" + test[\"r\"]\n",
        "test.tail(10)   #2387"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_data_q = test['q'].tolist()\n",
        "test_data_r = test['s+r'].tolist()\n",
        "test_q_reidx = test['q_reidx'].tolist()\n",
        "test_r_reidx = test['r_reidx'].tolist()\n",
        "test_encodings = tokenizer(test_data_q, test_data_r, truncation=True, padding=True, max_length=512, return_offsets_mapping=True)\n",
        "test_offset_mapping = test_encodings[\"offset_mapping\"]\n",
        "test_encodings.pop(\"offset_mapping\")\n",
        "test_encodings.keys()\n",
        "test_dataset = qrDataset(test_encodings)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0N3-L47N84Oh",
        "outputId": "af30e502-9d8e-47f0-f32b-6a9e69ba317f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 299/299 [00:42<00:00,  7.04it/s]\n"
          ]
        }
      ],
      "source": [
        "# q_sub_output, r_sub_output, predict_pos = predict(test_loader)\n",
        "predict_pos = predict(test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 21 13 34\n",
            "Would you accept civil unions even though they were less then marriage ? No ... and you do n't have to either .\n"
          ]
        }
      ],
      "source": [
        "q_sub, r_sub = [], []\n",
        "for i in range(len(predict_pos)):\n",
        "    if i == 2382:\n",
        "        print(predict_pos[i][0], predict_pos[i][1], predict_pos[i][2], predict_pos[i][3])\n",
        "    q_s = test_offset_mapping[i][predict_pos[i][0]][0]\n",
        "    q_e = test_offset_mapping[i][predict_pos[i][2]][-1]\n",
        "    r_s = test_offset_mapping[i][predict_pos[i][1]][0]\n",
        "    r_e = test_offset_mapping[i][predict_pos[i][3]][-1]\n",
        "    if i == 2382:\n",
        "        print(test_data_q[i][q_s:q_e], test_data_r[i][r_s:r_e])\n",
        "    q_pre_sen = test_data_q[i][q_s:q_e]\n",
        "    r_pre_sen = test_data_r[i][r_s:r_e]\n",
        "    q_sub.append(q_pre_sen)\n",
        "    r_sub.append(r_pre_sen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "couPbYb9obzZ"
      },
      "outputs": [],
      "source": [
        "test['q_sub'] = q_sub\n",
        "test['r_sub'] = r_sub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "test2 = test.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3890\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(2016, 2016, 2016)"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ans_id, ans_q, ans_r = [], [], []\n",
        "for id in set(test2[\"id\"]):\n",
        "    if id == 3890:\n",
        "        print(id)\n",
        "    frame = test2[test2[\"id\"] == id]\n",
        "    q_set =set(frame[\"q_sub_idx\"])\n",
        "    r_set =set(frame[\"r_sub_idx\"])\n",
        "    q_sub, r_sub = \"\", \"\"\n",
        "    if len(q_set) == 1:\n",
        "        q_sub = frame[\"q_sub\"].iloc[0]\n",
        "        if q_sub == \"\":\n",
        "            q_sub = frame[\"q\"].iloc[0]\n",
        "    else:\n",
        "        for idx in q_set:\n",
        "            # find max len by q_set to find in frame\n",
        "            q_frame = frame[frame[\"q_sub_idx\"] == idx]\n",
        "            max_idx = max(len(q) for q in q_frame[\"q_sub\"])\n",
        "            for q in q_frame[\"q_sub\"]:\n",
        "                if len(q) == max_idx:\n",
        "                    q_sub += q\n",
        "                    break\n",
        "    if len(q_sub) == 0:\n",
        "        if len(frame) == 1:\n",
        "            q_sub = frame[\"q_sub\"].iloc[0]\n",
        "        else:\n",
        "            q_sub = frame[\"q\"][frame[\"q\"].index[0]]\n",
        "            for idx, q in enumerate(frame[\"q\"][1:]):\n",
        "                if frame[\"q_sub_idx\"][frame[\"q\"].index[0]+idx+1] != frame[\"q_sub_idx\"][frame[\"q\"].index[0]+idx]:\n",
        "                    q_sub += q\n",
        "\n",
        "    if len(r_set) == 1:\n",
        "        r_sub = frame[\"r_sub\"].iloc[0]\n",
        "        if r_sub == \"\":\n",
        "            r_sub = frame[\"r\"].iloc[0]\n",
        "    else:\n",
        "        for idx in r_set:\n",
        "            # find max len by q_set to find in frame\n",
        "            r_frame = frame[frame[\"r_sub_idx\"] == idx]\n",
        "            max_idx = max(len(r) for r in r_frame[\"r_sub\"])\n",
        "            for r in r_frame[\"r_sub\"]:\n",
        "                if len(r) == max_idx:\n",
        "                    r_sub += r\n",
        "                    break\n",
        "\n",
        "    if len(r_sub) == 0:\n",
        "        if len(frame) == 1:\n",
        "            r_sub = frame[\"r_sub\"].iloc[0]\n",
        "        else:\n",
        "            r_sub = frame[\"r\"][frame[\"r\"].index[0]]\n",
        "            for idx, r in enumerate(frame[\"r\"][1:]):\n",
        "                if frame[\"r_sub_idx\"][frame[\"r\"].index[0]+idx+1] != frame[\"r_sub_idx\"][frame[\"r\"].index[0]+idx]:\n",
        "                    r_sub += r\n",
        "\n",
        "    ans_id.append(id)\n",
        "    ans_q.append('\"'+q_sub+'\"')\n",
        "    ans_r.append('\"'+r_sub+'\"')\n",
        "\n",
        "len(ans_id), len(ans_q), len(ans_r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "for q in ans_q:\n",
        "    if q == '\"\"':\n",
        "        print(q)\n",
        "\n",
        "for r in ans_r:\n",
        "    if r == '\"\"':\n",
        "        print(r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>q</th>\n",
              "      <th>r</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>\"I got a good idea . however , they do tend to...</td>\n",
              "      <td>\"By your own admission you havenÂ ’ t 'hung ou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>\"Be sure to give your guns a big fat kiss toni...</td>\n",
              "      <td>\"Actually , they did n't . The whole tragedy w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>\"One of the biggest arguments against gun cont...</td>\n",
              "      <td>\"Not quite . To be more correct regarding gove...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>\"compare the ' B ' specimen in your fossil lin...</td>\n",
              "      <td>\"Comparison I could 've just circled the whole...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>\"There are some incedents that are beyond your...</td>\n",
              "      <td>\"Well yes .\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011</th>\n",
              "      <td>8186</td>\n",
              "      <td>\"It seems that you would be willing to grant t...</td>\n",
              "      <td>\"Sorry to hear you lost an hour 's worth of wo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012</th>\n",
              "      <td>8187</td>\n",
              "      <td>\"Waiting until they are born likely gives them...</td>\n",
              "      <td>\"I think they have more of a chance becasue , ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013</th>\n",
              "      <td>8188</td>\n",
              "      <td>\"The government was right to tighten up the la...</td>\n",
              "      <td>\"So those who will allow more gun control , sh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014</th>\n",
              "      <td>8189</td>\n",
              "      <td>\"would you have a problem calling a guy marrag...</td>\n",
              "      <td>\"Yes , I would . The term is not simply just w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015</th>\n",
              "      <td>8190</td>\n",
              "      <td>\"This sedimentary layer would show signs of be...</td>\n",
              "      <td>\"It has been shown in evidence all around the ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2016 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                                  q  \\\n",
              "0        1  \"I got a good idea . however , they do tend to...   \n",
              "1        2  \"Be sure to give your guns a big fat kiss toni...   \n",
              "2        3  \"One of the biggest arguments against gun cont...   \n",
              "3        4  \"compare the ' B ' specimen in your fossil lin...   \n",
              "4        5  \"There are some incedents that are beyond your...   \n",
              "...    ...                                                ...   \n",
              "2011  8186  \"It seems that you would be willing to grant t...   \n",
              "2012  8187  \"Waiting until they are born likely gives them...   \n",
              "2013  8188  \"The government was right to tighten up the la...   \n",
              "2014  8189  \"would you have a problem calling a guy marrag...   \n",
              "2015  8190  \"This sedimentary layer would show signs of be...   \n",
              "\n",
              "                                                      r  \n",
              "0     \"By your own admission you havenÂ ’ t 'hung ou...  \n",
              "1     \"Actually , they did n't . The whole tragedy w...  \n",
              "2     \"Not quite . To be more correct regarding gove...  \n",
              "3     \"Comparison I could 've just circled the whole...  \n",
              "4                                          \"Well yes .\"  \n",
              "...                                                 ...  \n",
              "2011  \"Sorry to hear you lost an hour 's worth of wo...  \n",
              "2012  \"I think they have more of a chance becasue , ...  \n",
              "2013  \"So those who will allow more gun control , sh...  \n",
              "2014  \"Yes , I would . The term is not simply just w...  \n",
              "2015  \"It has been shown in evidence all around the ...  \n",
              "\n",
              "[2016 rows x 3 columns]"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ans = pd.DataFrame({\"id\": ans_id, \"q\": ans_q, \"r\": ans_r})\n",
        "# pd.set_option('display.max_colwidth', -1)\n",
        "ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "ans.to_csv(\"submission_bert_\"+best_model_name+\".csv\", index=False, encoding=\"utf-8\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6 (default, Aug  5 2022, 15:21:02) \n[Clang 14.0.0 (clang-1400.0.29.102)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
